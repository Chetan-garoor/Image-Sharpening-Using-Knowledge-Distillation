# -*- coding: utf-8 -*-
"""Imagesharpening final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OBCrwuGKD8IfWsJ2xDtsJrGjaT98dh8e

2nd

3
"""

# Step 1: Install required packages
!pip install torch torchvision torchaudio
!pip install opencv-python matplotlib scikit-image
!pip install pytorch_msssim timm einops tqdm

# Step 2: Import libraries
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision.datasets import CIFAR10
from torchvision.utils import save_image
import cv2
import numpy as np
import os
import matplotlib.pyplot as plt
from pytorch_msssim import ssim
from glob import glob
import random
from PIL import Image, ImageFilter
from tqdm import tqdm
import shutil

# Step 3: Create synthetic dataset
def create_synthetic_dataset():
    os.makedirs("synthetic_dataset/train/sharp", exist_ok=True)
    os.makedirs("synthetic_dataset/train/blur", exist_ok=True)
    os.makedirs("synthetic_dataset/test/sharp", exist_ok=True)
    os.makedirs("synthetic_dataset/test/blur", exist_ok=True)

    # Download CIFAR10 - no need for ToPILImage conversion
    train_data = CIFAR10(root='./data', train=True, download=True)
    test_data = CIFAR10(root='./data', train=False, download=True)

    print("Creating training dataset...")
    for i in tqdm(range(1000)):  # 1000 training samples
        sharp_img = train_data[i][0]  # Already a PIL Image

        # Create blurry version
        blur_img = sharp_img.filter(ImageFilter.GaussianBlur(radius=random.uniform(1.5, 3.0)))

        sharp_img.save(f"synthetic_dataset/train/sharp/{i}.png")
        blur_img.save(f"synthetic_dataset/train/blur/{i}.png")

    print("Creating test dataset...")
    for i in tqdm(range(100)):  # 100 test samples
        sharp_img = test_data[i][0]  # Already a PIL Image

        # Create blurry version
        blur_img = sharp_img.filter(ImageFilter.GaussianBlur(radius=random.uniform(1.5, 3.0)))

        sharp_img.save(f"synthetic_dataset/test/sharp/{i}.png")
        blur_img.save(f"synthetic_dataset/test/blur/{i}.png")

    print("Synthetic dataset created!")

# Create dataset
create_synthetic_dataset()

# Step 4: Dataset and DataLoader
class ImageSharpeningDataset(Dataset):
    def __init__(self, blur_path, sharp_path, transform=None):
        self.blur_images = sorted(glob(f"{blur_path}/*.png"))
        self.sharp_images = sorted(glob(f"{sharp_path}/*.png"))
        self.transform = transform

    def __len__(self):
        return len(self.blur_images)

    def __getitem__(self, idx):
        blur_img = Image.open(self.blur_images[idx]).convert("RGB")
        sharp_img = Image.open(self.sharp_images[idx]).convert("RGB")

        if self.transform:
            blur_img = self.transform(blur_img)
            sharp_img = self.transform(sharp_img)

        return blur_img, sharp_img

# Define transforms
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Create datasets and dataloaders
train_dataset = ImageSharpeningDataset(
    "synthetic_dataset/train/blur",
    "synthetic_dataset/train/sharp",
    transform
)
val_dataset = ImageSharpeningDataset(
    "synthetic_dataset/test/blur",
    "synthetic_dataset/test/sharp",
    transform
)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)

# Step 5: Teacher Model (Simplified Restormer)
class ResidualBlock(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)
        self.relu = nn.ReLU()
        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)

    def forward(self, x):
        residual = x
        out = self.relu(self.conv1(x))
        out = self.conv2(out)
        out += residual
        return out

class TeacherModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.initial = nn.Conv2d(3, 64, kernel_size=3, padding=1)
        self.res_blocks = nn.Sequential(
            *[ResidualBlock(64) for _ in range(8)]
        )
        self.final = nn.Conv2d(64, 3, kernel_size=3, padding=1)

    def forward(self, x):
        x = self.initial(x)
        x = self.res_blocks(x)
        x = self.final(x)
        return x

teacher = TeacherModel().cuda()

# Step 6: Student Model (Lightweight CNN)
class StudentModel(nn.Module):
    def __init__(self):
        super().__init__()
        # Encoder
        self.enc1 = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.ReLU()
        )
        self.down1 = nn.MaxPool2d(2)

        self.enc2 = nn.Sequential(
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.ReLU()
        )
        self.down2 = nn.MaxPool2d(2)

        # Bottleneck
        self.bottleneck = nn.Sequential(
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.ReLU()
        )

        # Decoder
        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)
        self.dec1 = nn.Sequential(
            nn.Conv2d(128, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.ReLU()
        )

        self.up2 = nn.ConvTranspose2d(64, 32, 2, stride=2)
        self.dec2 = nn.Sequential(
            nn.Conv2d(64, 32, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.ReLU()
        )

        self.final = nn.Conv2d(32, 3, 1)

    def forward(self, x):
        # Encoder
        e1 = self.enc1(x)
        d1 = self.down1(e1)

        e2 = self.enc2(d1)
        d2 = self.down2(e2)

        # Bottleneck
        b = self.bottleneck(d2)

        # Decoder
        u1 = self.up1(b)
        u1 = torch.cat([u1, e2], dim=1)
        d1 = self.dec1(u1)

        u2 = self.up2(d1)
        u2 = torch.cat([u2, e1], dim=1)
        d2 = self.dec2(u2)

        return self.final(d2)

student = StudentModel().cuda()
print(f"Student parameters: {sum(p.numel() for p in student.parameters()):,}")

# Step 7: Knowledge Distillation Implementation
class DistillationLoss(nn.Module):
    def __init__(self, alpha=0.5, beta=0.3, gamma=0.2):
        super().__init__()
        self.alpha = alpha  # Reconstruction weight
        self.beta = beta    # Perceptual weight
        self.gamma = gamma  # Output distillation weight
        self.l1_loss = nn.L1Loss()

        # VGG for perceptual loss
        self.vgg = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)
        self.vgg = nn.Sequential(*list(self.vgg.features)[:16]).eval().cuda()
        for param in self.vgg.parameters():
            param.requires_grad = False

    def perceptual_loss(self, x, y):
        return self.l1_loss(self.vgg(x), self.vgg(y))

    def forward(self, student_out, sharp_img, teacher_out):
        # Reconstruction loss
        rec_loss = self.l1_loss(student_out, sharp_img)

        # Perceptual loss
        perc_loss = self.perceptual_loss(student_out, sharp_img)

        # Output distillation
        distill_loss = self.l1_loss(student_out, teacher_out.detach())

        return (
            self.alpha * rec_loss +
            self.beta * perc_loss +
            self.gamma * distill_loss
        )

# Step 10: Evaluation Functions (Moved Up)
def evaluate(model, loader):
    model.eval()
    total_ssim = 0.0

    with torch.no_grad():
        for blur, sharp in loader:
            blur = blur.cuda()
            sharp = sharp.cuda()

            output = model(blur)

            # Denormalize
            output = (output + 1) / 2
            sharp = (sharp + 1) / 2

            batch_ssim = ssim(output, sharp, data_range=1.0, size_average=True)
            total_ssim += batch_ssim.item()

    return total_ssim / len(loader)

def visualize_results(model, loader, num_samples=3):
    model.eval()
    with torch.no_grad():
        for i, (blur, sharp) in enumerate(loader):
            if i >= num_samples:
                break

            blur = blur.cuda()
            output = model(blur)

            # Convert to numpy
            blur_np = blur[0].cpu().numpy().transpose(1,2,0)
            sharp_np = sharp[0].numpy().transpose(1,2,0)
            output_np = output[0].cpu().numpy().transpose(1,2,0)

            # Denormalize
            blur_np = (blur_np * 0.5 + 0.5)
            sharp_np = (sharp_np * 0.5 + 0.5)
            output_np = (output_np * 0.5 + 0.5)

            # Clip to [0,1] range
            blur_np = np.clip(blur_np, 0, 1)
            sharp_np = np.clip(sharp_np, 0, 1)
            output_np = np.clip(output_np, 0, 1)

            # Plot
            plt.figure(figsize=(15, 5))
            plt.subplot(131)
            plt.title("Blurry Input")
            plt.imshow(blur_np)
            plt.axis('off')

            plt.subplot(132)
            plt.title("Student Output")
            plt.imshow(output_np)
            plt.axis('off')

            plt.subplot(133)
            plt.title("Sharp Target")
            plt.imshow(sharp_np)
            plt.axis('off')

            plt.show()

# Step 8: Train Teacher Model
def train_teacher(model, loader, epochs=10):
    optimizer = optim.Adam(model.parameters(), lr=1e-4)
    criterion = nn.L1Loss()

    for epoch in range(epochs):
        model.train()
        total_loss = 0.0

        for blur, sharp in tqdm(loader, desc=f"Training Teacher Epoch {epoch+1}/{epochs}"):
            blur = blur.cuda()
            sharp = sharp.cuda()

            optimizer.zero_grad()
            output = model(blur)

            loss = criterion(output, sharp)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        avg_loss = total_loss / len(loader)
        print(f"Epoch [{epoch+1}/{epochs}] Teacher Loss: {avg_loss:.4f}")

        # Evaluate
        if (epoch+1) % 5 == 0 or epoch == epochs-1:
            ssim_score = evaluate(model, val_loader)
            print(f"Teacher SSIM: {ssim_score:.4f}")
            torch.save(model.state_dict(), f"teacher_epoch_{epoch+1}.pth")

    return model

print("Training teacher model...")
teacher = train_teacher(teacher, train_loader, epochs=20)

# Step 9: Train Student with Knowledge Distillation
def train_student(student, teacher, loader, epochs=50):
    optimizer = optim.Adam(student.parameters(), lr=1e-4)
    criterion = DistillationLoss(alpha=0.5, beta=0.3, gamma=0.2)

    best_ssim = 0.0

    for epoch in range(epochs):
        student.train()
        total_loss = 0.0

        for blur, sharp in tqdm(loader, desc=f"Training Student Epoch {epoch+1}/{epochs}"):
            blur = blur.cuda()
            sharp = sharp.cuda()

            with torch.no_grad():
                teacher_out = teacher(blur)

            optimizer.zero_grad()
            student_out = student(blur)

            loss = criterion(student_out, sharp, teacher_out)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        avg_loss = total_loss / len(loader)
        print(f"Epoch [{epoch+1}/{epochs}] Student Loss: {avg_loss:.4f}")

        # Evaluate and save best model
        if (epoch+1) % 5 == 0 or epoch == epochs-1:
            ssim_score = evaluate(student, val_loader)
            print(f"Student SSIM: {ssim_score:.4f}")

            if ssim_score > best_ssim:
                best_ssim = ssim_score
                torch.save(student.state_dict(), "best_student.pth")
                print("Saved best student model!")

    return student

print("Training student model with knowledge distillation...")
student = train_student(student, teacher, train_loader, epochs=50)

# Step 11: Evaluate and Visualize
print("Evaluating models...")
teacher_ssim = evaluate(teacher, val_loader)
student_ssim = evaluate(student, val_loader)
print(f"Teacher SSIM: {teacher_ssim:.4f}")
print(f"Student SSIM: {student_ssim:.4f}")

print("Visualizing results...")
visualize_results(student, val_loader)

# Step 12: Save and Test with Custom Image
def test_custom_image(image_path, model):
    # Load and preprocess image
    img = Image.open(image_path).convert("RGB")
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])
    img_tensor = transform(img).unsqueeze(0).cuda()

    # Process
    with torch.no_grad():
        output = model(img_tensor)

    # Convert to numpy
    output = output.squeeze(0).cpu().numpy().transpose(1,2,0)
    output = (output * 0.5 + 0.5) * 255
    output = np.clip(output, 0, 255).astype(np.uint8)

    # Convert to PIL image
    output_img = Image.fromarray(output)

    # Save and display
    output_img.save("sharpened_result.jpg")

    plt.figure(figsize=(10, 5))
    plt.subplot(121)
    plt.title("Original")
    plt.imshow(img)
    plt.axis('off')

    plt.subplot(122)
    plt.title("Sharpened")
    plt.imshow(output_img)
    plt.axis('off')

    plt.show()
    return output_img

# Example usage (upload your own image to Colab)
# test_custom_image("your_image.jpg", student)

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')
print("Google Drive mounted successfully!")

from google.colab import drive
import os
import shutil

# Step 1: Mount Google Drive
drive.mount('/content/drive')
print("Google Drive mounted successfully!")

# Step 2: Define the Destination Path in Google Drive
drive_path = '/content/drive/My Drive/sharpening_models'
os.makedirs(drive_path, exist_ok=True)
print(f"Drive directory '{drive_path}' ensured.")

# Step 3: Copy Your Models to Google Drive
student_model_source = 'best_student.pth'
teacher_model_source = 'teacher_epoch_20.pth' # Adjust if your teacher model name is different

student_model_dest = os.path.join(drive_path, 'best_student.pth')
teacher_model_dest = os.path.join(drive_path, 'teacher_epoch_20.pth')

if os.path.exists(student_model_source):
    shutil.copy(student_model_source, student_model_dest)
    print(f"'{student_model_source}' copied to '{student_model_dest}'")
else:
    print(f"Warning: '{student_model_source}' not found. Skipping copy.")

if os.path.exists(teacher_model_source):
    shutil.copy(teacher_model_source, teacher_model_dest)
    print(f"'{teacher_model_source}' copied to '{teacher_model_dest}'")
else:
    print(f"Warning: '{teacher_model_source}' not found. Skipping copy.")

print("\nModel upload process completed.")



print("\n--- Testing with Custom Images ---")

def test_custom_image(image_path, model):
    """
    Tests the trained model on a custom input image, displays the original
    and sharpened results, and saves the sharpened image.

    Args:
        image_path (str): Path to the input blurry image.
        model (torch.nn.Module): The trained image sharpening model.
    """
    # Load and preprocess image
    try:
        img = Image.open(image_path).convert("RGB")
    except FileNotFoundError:
        print(f"Error: Image not found at {image_path}. Please check the path and filename.")
        return

    transform = transforms.Compose([
        transforms.Resize((256, 256)), # Ensure consistent input size for the model
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])
    img_tensor = transform(img).unsqueeze(0).cuda() # Add batch dimension and move to GPU

    # Process
    model.eval() # Set the model to evaluation mode
    with torch.no_grad(): # Disable gradient calculation for inference
        output = model(img_tensor)

    # Convert output tensor to numpy array for visualization
    output = output.squeeze(0).cpu().numpy().transpose(1,2,0) # Remove batch, move to CPU, change to HWC

    # Denormalize the output image from [-1, 1] to [0, 255]
    output = (output * 0.5 + 0.5) * 255
    output = np.clip(output, 0, 255).astype(np.uint8) # Clip to valid pixel range and convert to uint8

    # Convert to PIL image for saving/displaying
    output_img = Image.fromarray(output)

    # Save the sharpened result
    output_filename = "sharpened_custom_result.jpg" # Changed filename to avoid overwriting
    output_img.save(output_filename)
    print(f"Sharpened image saved as: {output_filename}")

    # Display original and sharpened images
    plt.figure(figsize=(12, 6))
    plt.subplot(121)
    plt.title("Original Custom Image")
    plt.imshow(img)
    plt.axis('off')

    plt.subplot(122)
    plt.title("Sharpened Custom Output")
    plt.imshow(output_img)
    plt.axis('off')

    plt.show()

    return output_img

# --- IMPORTANT: CHANGE THIS TO THE PATH OF YOUR OWN BLURRY IMAGE ---
CUSTOM_IMAGE_PATH = '/content/79265265-blurred-of-red-dog images test.jpg' # Example: 'my_test_blur.png'

# Call the function to test with your custom image
test_custom_image(CUSTOM_IMAGE_PATH, student) # Test the student model
# test_custom_image(CUSTOM_IMAGE_PATH, teacher) # Uncomment to test the teacher model too